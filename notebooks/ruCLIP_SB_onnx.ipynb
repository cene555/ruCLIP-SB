{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ruCLIP_SB_onnx.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WWXCt_2NLhN_",
        "PHb4CAoRL3qC",
        "re2sSYAYO3D-",
        "ithu4-z0PIm5",
        "FWm0GAhWPzSW"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cene555/ruCLIP-SB/blob/main/notebooks/ruCLIP_SB_onnx.ipynb)"
      ],
      "metadata": {
        "id": "JsWuTduwaagq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Allowed Resources\n",
        "import multiprocessing\n",
        "import torch\n",
        "from psutil import virtual_memory\n",
        "\n",
        "ram_gb = round(virtual_memory().total / 1024**3, 1)\n",
        "\n",
        "print('CPU:', multiprocessing.cpu_count())\n",
        "print('RAM GB:', ram_gb)\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA version:\", torch.version.cuda)\n",
        "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device.type)\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xdy_cPJEYXV",
        "outputId": "18168553-b4ec-41e9-f966-9efa9db2fd33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: 2\n",
            "RAM GB: 12.7\n",
            "PyTorch version: 1.10.0+cu111\n",
            "CUDA version: 11.1\n",
            "cuDNN version: 8005\n",
            "device: cuda\n",
            "Tue Jan 25 17:45:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    28W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ],
      "metadata": {
        "id": "WWXCt_2NLhN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/cene555/ruCLIP-SB.git\n",
        "!pip install pymorphy2\n",
        "!gdown -O ruCLIP-SB.pkl https://drive.google.com/uc?id=1-CghuC9TCIDyn5H3zQS6ho_TNiudzJCX\n",
        "\n",
        "!pip install git+https://github.com/Lednik7/CLIP-ONNX.git\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install onnxruntime-gpu\n",
        "\n",
        "!wget -c -O CLIP.png https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true"
      ],
      "metadata": {
        "id": "FWEEtd7Vryaf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "PHb4CAoRL3qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from ruclipsb import ruCLIPSB\n",
        "from ruclipsb.utils import tokenize, _convert_image_to_rgb\n",
        "from PIL import ImageCms, Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "try:\n",
        "    from torchvision.transforms import InterpolationMode\n",
        "    BICUBIC = InterpolationMode.BICUBIC\n",
        "except ImportError:\n",
        "    BICUBIC = Image.BICUBIC"
      ],
      "metadata": {
        "id": "cznZ7ozDL5-M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "Q1JZTGGvWVNC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "QXNtl3gNRiRr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load RuCLIP-SB model"
      ],
      "metadata": {
        "id": "ithu4-z0PIm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ruCLIPSB()\n",
        "model.load_state_dict(torch.load('ruCLIP-SB.pkl', map_location=device))\n",
        "model = model.half().to(device)\n",
        "\n",
        "model = model.eval()\n",
        "for x in model.parameters(): x.requires_grad = False\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWrR6BzhPKji",
        "outputId": "1f6e05e8-2f5e-401d-a7be-3e9f2be0a71c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")"
      ],
      "metadata": {
        "id": "0eniQ2HTQggY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            _convert_image_to_rgb,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),])"
      ],
      "metadata": {
        "id": "RaFNlbHpQj7i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare functions"
      ],
      "metadata": {
        "id": "3PlskeIMYmxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch first\n",
        "image = transform(Image.open(\"CLIP.png\")).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
        "image_onnx = image.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "# batch first\n",
        "texts = ['диаграмма', 'собака', 'кошка']\n",
        "text_tokens, attention_mask = tokenize(tokenizer, texts, 77)\n",
        "text_tokens, attention_mask = text_tokens.cpu(), attention_mask.cpu() # [3, 77]\n",
        "text_onnx = torch.stack([text_tokens, attention_mask]).detach().cpu().numpy().astype(np.int64)"
      ],
      "metadata": {
        "id": "H3mN8xVnWj9M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Textual(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        input_ids, attention_mask = input_data\n",
        "        x = self.model.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        x = x.last_hidden_state[:, 0, :]\n",
        "        x = self.model.final_ln(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DcnycYuYF6w1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert RuCLIP-SB model to ONNX"
      ],
      "metadata": {
        "id": "WmITDkxDYsv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from clip_onnx import clip_onnx\n",
        "\n",
        "def convert_textual(self, dummy_input):\n",
        "    textual = Textual(self.model)\n",
        "    torch.onnx.export(textual, dummy_input, self.textual_path,\n",
        "                  input_names=['input'], output_names=['output'],\n",
        "                  export_params=True, verbose=False, opset_version=14,\n",
        "                  do_constant_folding=True,\n",
        "                  dynamic_axes={'input': {1: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
        "    self.onnx_checker(self.textual_path)\n",
        "\n",
        "clip_onnx.convert_textual = convert_textual\n",
        "\n",
        "visual_path = \"clip_visual.onnx\"\n",
        "textual_path = \"clip_textual.onnx\"\n",
        "\n",
        "dummy_input_text = torch.stack([text_tokens, attention_mask]).detach().cpu()"
      ],
      "metadata": {
        "id": "zUUu9wCZCFEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = clip_onnx(model.float().cpu(), visual_path=visual_path, textual_path=textual_path)\n",
        "onnx_model.convert2onnx(image, dummy_input_text, verbose=True)"
      ],
      "metadata": {
        "id": "-TBIiGzwYKMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [ONNX] CUDA inference mode"
      ],
      "metadata": {
        "id": "_KWnKarOY6t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
        "onnx_model.start_sessions(providers=[\"CUDAExecutionProvider\"]) # cuda mode"
      ],
      "metadata": {
        "id": "06Y5KogAY6Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_features = onnx_model.encode_image(image_onnx)\n",
        "text_features = onnx_model.encode_text(text_onnx)\n",
        "\n",
        "logits_per_image, logits_per_text = onnx_model(image_onnx, text_onnx)\n",
        "probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()\n",
        "\n",
        "print(\"Label probs:\", probs) # [[0.9844646  0.01167088 0.00386453]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM_vMne7MGEu",
        "outputId": "a6ecd7d4-ed50-48e4-b098-82aedf321fc7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label probs: [[0.9844646  0.01167088 0.00386453]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit onnx_model.encode_image(image_onnx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCzqP0wDYXdt",
        "outputId": "9a1ea435-f4d8-4f16-b0f0-712bdd457947"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 18 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit onnx_model.encode_text(text_onnx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zYofeqqYco8",
        "outputId": "ed1f7195-eb0a-4982-eab1-689e30e2bec6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 2.76 ms per loop\n"
          ]
        }
      ]
    }
  ]
}