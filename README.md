# ruCLIP-SB
RuCLIP-SB (Russian Contrastive Languageâ€“Image Pretraining SWIN-BERT) is a multimodal model for obtaining images and text similarities and rearranging captions and pictures. Unlike other versions of the model we use BERT for text encoder and SWIN transformer for image encoder. 

## Our model achieved 37.02% zero-shot accuracy on CIFAR100 and has 39543907 parameters. 
### Download URL: [ruCLIP-SB](https://drive.google.com/file/d/1-CghuC9TCIDyn5H3zQS6ho_TNiudzJCX/view?usp=sharing)

### Example usage: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cene555/ruCLIP-SB/blob/main/notebooks/evaluate_ruCLIP_SB_latest.ipynb)

### Finetuning: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1iGIfr9XD7wQi3rGZjmx1bmm2_qDg9qYy?usp=sharing)

### ONNX example: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cene555/ruCLIP-SB/blob/main/notebooks/ruCLIP_SB_onnx.ipynb)

We trained model on 2 millions images.

![image](https://github.com/cene555/ruCLIP-SB/blob/main/pictures/Similarity.png)


### Thanks to Sber AI for help.
